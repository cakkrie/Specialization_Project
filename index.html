<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Cornell Tech Design Tech Project</title>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;700&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <div class="left">Cornell Tech</div>
    <div class="center">
      Design Tech<br>
      <span>Project Archive</span>
    </div>
    <div class="right"><a href="#">About</a></div>
  </header>

  <main>
    <div class="project-meta">2025</div>
    <div class="project-title">Design Tech Project</div>
    <div class="course-info">DESIGN 8131 Specialization Project 1</div>
    <div class="project-subtitle">Jinyue (Carrie) Wang, jw2796@cornell.edu | Wing Sze (Sissi) Zheng, wz472@cornell.edu</div>
    <div class="advisor">Advisor<br><strong>Jose Sanchez</strong></div>

    <hr style="border: 0; border-top: 1px solid #333; margin: 32px 0;">

    <div class="section-title">Project Questions</div>
    <div class="section-subtitle">Long Latency</div>


    <!-- Labels -->
    <span class="label outline info">Multi-sensor</span>
    <span class="label outline info">Communication</span>
    <span class="label outline info">Scientific Research</span>
    
    <span class="label outline">Physicalization</span>
    <span class="label outline">Play</span>

    <p>As AI systems take on increasingly complex tasks, the computational resources required to process them grow substantially. This often leads to extended response latency in AI products. Such delays present several challenges for user experience.</p>

    <p>*First, long waiting times test user patience and can lead to frustration, abandonment of tasks, or diminished trust in the system.*Second, interruptions caused by latency disrupt cognitive flow, making it harder for users to maintain continuity in thought and workflow. *Finally, without clear feedback about the system’s current state, users face uncertainty over whether the AI is still processing, stalled, or has failed altogether.</p>

     <!-- Question -->
    <div class="callout">
      <p>How might we reframe latency from a passive waiting period into an active part of the interaction that sustains engagement and confidence in AI product?</p>
    </div>

    <br>
    <div class="section-subtitle">Cognitive difference between stakeholders in AI products</div>

    <!-- Labels -->
    <span class="label outline info">Communication</span>
    <span class="label outline info">Accessibility</span>
    <span class="label outline info">Connectivity</span>
    <span class="label outline info">Scalability</span>
    
    <p>Given the rapid iteration and development of AI models, each serves different disciplines with distinct strengths—for example, code decomposition, visual design, or other specialized tasks.</p>

    <p>While OpenAI has released a leaderboard that is widely accepted in the industry, its benchmarks are primarily designed for ML engineering rather than general users. As a result, users struggle to identify which model best fits their specific needs in this fast-evolving landscape, since different stakeholders prioritize different functions and evaluation dimensions.</p>

    <p>Addressing this gap could help close the cognitive divide between AI products and their consumers. </p>

    <div class="callout">
      <p>How might we design user-friendly evaluation frameworks that help non-expert users identify which AI model best fits their task needs in a rapidly evolving landscape of specialized models?</p>
    </div>

    <br>
    <br>
    <div class="section-title">State of Knowledge of the field</div>
    
    <div class="knowledge-container">
      <div class="knowledge-column">
        <div class="person-header">
          <h3>Carrie Wang</h3>
          <span class="person-role">Design & User Experience</span>
        </div>
        <div class="knowledge-areas">
          <div class="knowledge-item">
            <h4>Mobile/Web UIUX</h4>
            <div class="skill-level expert">Expert</div>
          </div>
          <div class="knowledge-item">
            <h4>AI/ML Concepts</h4>
            <div class="skill-level intermediate">Intermediate</div>
          </div>
          <div class="knowledge-item">
            <h4>Product Management</h4>
            <div class="skill-level beginner">Intermediate</div>
          </div>
          <div class="knowledge-item">
            <h4>Hardware interaction</h4>
            <div class="skill-level beginner">Beginner</div>
          </div>
        </div>
      </div>
      
      <div class="knowledge-column">
        <div class="person-header">
          <h3>Sissi Zheng</h3>
          <span class="person-role">Technical & Research</span>
        </div>
        <div class="knowledge-areas">
          <div class="knowledge-item">
            <h4>Software/Hardware interaction</h4>
            <div class="skill-level expert">Expert</div>
          </div>
          <div class="knowledge-item">
            <h4> voice AI interaction </h4>
            <div class="skill-level expert">Expert</div>
          </div>
          <div class="knowledge-item">
            <h4>LLM</h4>
            <div class="skill-level intermediate">Intermediate</div>
          </div>
        </div>
      </div>
    </div>

    <br>
    <br>
    <div class="section-title">Map of Community of Practice</div>
    <div class="section-subtitle">Long Latency</div>

    <p><b>Current Companies & Solutions:</b>

    <b>Engineering + Infrastructure Optimizations:</b>
    <br>
    Uber: The AI team at Uber’s Development Platform: When handling large-scale operations such as code migration and real-time data querying, this effectively mitigates blocking caused by single-point latency and significantly improves system response speed.
    <br>
    Amazon: offers latency-optimized inference modes to accelerate response times when using LLMs, crucial for improving UX in real-time applications.
    <br>
    Lepton AI: allowing the AI to start responding within 300 milliseconds to a "think-while-speaking" function
    
    <br>
    <br>
    <b>UX / Design Strategies:</b>
    <br>
    Ricky Ho: Fast vs. Slow Path Design: pre-defined flow graphs and intent detection to route simple requests (e.g., weather) through fast paths and complex tasks to LLMs only if needed
    <br>
    Procreator / Duolingo: Infuses empathy into latency UX with friendly micro-copy and humanized messaging
    <br>
    Morgan Stanley / BofA: Embeds UX guidance into workflows & trains users (especially leadership) to manage AI expectations</p>

    <br>
    <div class="section-subtitle">Cognitive Difference</div>

    <p><b>Black Box and Model Evaluation Issues:</b>
    <br>
    Google Vertex Explainable AI: explain the important features of model input and output, and can conduct comparison, evaluation, and prompt optimization for generative models
    <br>
    Rawbot: A toC model comparison platform that showcases the differences between models such as GPT, Claude, and Cohere across multiple tasks
    <br>
    InterpretML: A toolkit to help understand models and enable responsible machine learning
    <br>
    LMArena: Compare answers across top AI models, share your feedback and power our public
    <br>
    <br>
    <b>The Community:</b>
    <ul>
      <li>AI Engineers / Model Developers</li>
      <li>UX / Product Designer</li>
      <li>Infrastructure / DevOps Teams</li>
      <li>Industry Regulators</li>
      <li>End User</li>
    </ul>    

</body>
</html>
